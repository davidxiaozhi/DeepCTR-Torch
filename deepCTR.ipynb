{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里我们使用别人已经编写的 deepCTR 库.来验证 din 深度学习兴趣网络 [中文知乎地址](https://zhuanlan.zhihu.com/p/53231955), 英文知乎地址 [英文知乎地址](https://zhuanlan.zhihu.com/p/53231955)\n",
    "\n",
    "具体的依赖安装\n",
    "\n",
    "pip install deepctr[cpu]#cpu版本\n",
    "\n",
    "pip install deepctr[gpu]#GPU版本\n",
    "\n",
    "对应 torch 要添加 torch\n",
    "pip  install deepctr-torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "我们简单了解一下 deepCTR 的核心设计\n",
    "首先在设计过程中采用模块化的设计,各个模块相互独立,基于深度学习的点击率预测模型按模型内部组件的功能可以划分成以下4个模块：输入模块，嵌入模块，特征提取模块，预测输出模块。\n",
    "\n",
    "![模块化设计](https://pic1.zhimg.com/80/v2-392784585d6238db7f20744e8e98c5f4_1440w.jpg \"Magic Gardens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "python 当中的多根工作区配置 https://code.visualstudio.com/docs/editor/multi-root-workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 mac ```m1```  进行 python 开发的时候,需要踩坑就是 官方的 conda 并不支持 mac m1 版本,所以很多软件并不能正常运行,例如 TensorFlow pytorch 等,这里我们使用支持的m1 conda  [支持mac\n",
    "_m1的 conda](https://github.com/conda-forge/miniforge/#download) ,这里安装尽可能使用 \n",
    "```shell\n",
    "conda install -c conda-forge tqdm\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 vscode 开发需要注意两点\n",
    "\n",
    "1.vscode 的 setting.json 配置说明,后续补充连接\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"python.pythonPath\": \"$HOME/miniconda3/envs/deepctr/bin/python\",\n",
    "}\n",
    "```\n",
    "另外一个示例\n",
    "```json\n",
    "{\n",
    "    \"python.autoComplete.extraPaths\": [\"${workspaceFolder}/deepctr_torch\"],\n",
    "    \"python.envFile\": \"${workspaceFolder}/.env\",\n",
    "    \"python.analysis.extraPaths\": [\n",
    "        \"${workspaceFolder}/deepctr_torch\"\n",
    "    ],\n",
    "    \"jupyter.jupyterServerType\": \"local\",\n",
    "    \"terminal.integrated.env.osx\": {\"PYTHONPATH\": \"${workspaceFolder}${pathSeparator}${env:PYTHONPATH}\"}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.launcher.json 配置说明\n",
    "\n",
    "```json \n",
    "{\n",
    "    // Use IntelliSense to learn about possible attributes.\n",
    "    // Hover to view descriptions of existing attributes.\n",
    "    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"configurations\": [\n",
    "        {\n",
    "            \"name\": \"Python: 当前文件\",\n",
    "            \"type\": \"python\",\n",
    "            \"request\": \"launch\",\n",
    "            \"program\": \"${file}\",\n",
    "            \"console\": \"integratedTerminal\",\n",
    "            \"justMyCode\": true,\n",
    "            \"cwd\": \"${fileDirname}\",\n",
    "            \"env\": {\"PYTHONPATH\": \"${workspaceFolder}${pathSeparator}${env:PYTHONPATH}\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "# 在线模式不要使用,下面画图 使用 plotly 离线模式\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=False)\n",
    "#import chart_studio.plotly as py #在线模式不用使用,很卡\n",
    "import plotly.figure_factory as ff\n",
    "# 配置pandas 的默认绘图使用 plotly\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "# 引入高级绘图模式 plotly.express ,低级别的绘图模式是 plotly.graph_objs\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 使用pandas 读取上面介绍的数据，并进行简单的缺失值填充\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.models import *\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "! \\rm -vf ./data/criteo_sample.txt\n",
    "! wget https://github.com/shenweichen/DeepCTR-Torch/blob/master/examples/criteo_sample.txt -O ./data/criteo_sample.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 使用pandas 读取上面介绍的数据，并进行简单的缺失值填充\n",
    "data = pd.read_csv('./data/criteo_sample.txt')\n",
    "# 上面的数据在：https://github.com/shenweichen/DeepCTR-Torch/blob/master/examples/criteo_sample.txt\n",
    "table = ff.create_table(data.head(10))\n",
    "py.iplot(table, filename='jupyter-table1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "source": [
    "使用 pandas+polly 注意是为了针对数据做统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16],mode='markers')\n",
    "layout=go.Layout(title='Hello Plotly!!', xaxis=dict(title='x axis'), yaxis=dict(title='y axis'))\n",
    "#一个 Figure 对象要包含三部分 data layout 和 frames, 其中 data 和 layout 可以是空的,后续可以动态更新\n",
    "fig=go.Figure(data=[trace1],layout=layout)\n",
    "#如果想查看数据可以使用 print(fig.to_json())\n",
    "# 使用 fig.show() 显示图表也可以\n",
    "py.iplot(fig, filename='jupyter-plot1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们继续回到 deepCTR的案例上来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征列添加标志27 个稀疏特征, 14 个稠密特征, 我们给稀疏特征 添加 C 的标志,给稠密特征添加 I 的标志\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征缺失值处理 稀疏值 补充-1,稠密特征缺失值处理 填充0\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里我们需要对特征进行一些预处理，对于类别特征，我们使用LabelEncoder重新编码(或者哈希编码)，对于数值特征使用MinMaxScaler压缩到0~1之间。\n",
    "# 这里我们使用的 sklearn 的 LabelEncoder 对类别特征进行编码,使用的 MinMaxScaler 讲数值特征压缩到0~1之间\n",
    "for feat in sparse_features:\n",
    "   lbe = LabelEncoder()\n",
    "   data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是比较关键的一步，因为我们需要对类别特征进行Embedding，所以需要告诉模型每一个特征组有多少个embbedding向量，我们通过pandas的nunique()方法统计。\n",
    "# SparseFeat(特征名称,特征维度,embedding_size,embedding_name) 这里采用的是命名元组实现的\n",
    "# DensFeat(特征名称,特征维度)\n",
    "# 核心逻辑将 稀疏特征 和 稠密特征进行拼接 \n",
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique()) for feat in sparse_features] + [ DenseFeat(feat, 1,) for feat in dense_features]\n",
    "\n",
    "# 深度学习模型的特征输入 \n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "# 线性模型的输入\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "# 输入特征的名称\n",
    "fixlen_feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "fixlen_feature_names[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#最后，我们按照上一步生成的特征列拼接数据\n",
    "# 8 2 原则拆分训练集和验证集\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "train_model_input = [train[name] for name in fixlen_feature_names]\n",
    "test_model_input = [test[name] for name in fixlen_feature_names]\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "   print('cuda ready...')\n",
    "   device = 'cuda:0'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "67s - loss:  0.0539 - binary_crossentropy:  0.0539 - auc:  1.0000 - val_binary_crossentropy:  0.8821 - val_auc:  0.3864\n",
      "Epoch 14/100\n",
      "69s - loss:  0.0434 - binary_crossentropy:  0.0434 - auc:  1.0000 - val_binary_crossentropy:  0.9054 - val_auc:  0.3773\n",
      "Epoch 15/100\n",
      "68s - loss:  0.0353 - binary_crossentropy:  0.0353 - auc:  1.0000 - val_binary_crossentropy:  0.9274 - val_auc:  0.3727\n",
      "Epoch 16/100\n",
      "66s - loss:  0.0291 - binary_crossentropy:  0.0291 - auc:  1.0000 - val_binary_crossentropy:  0.9492 - val_auc:  0.3727\n",
      "Epoch 17/100\n",
      "68s - loss:  0.0243 - binary_crossentropy:  0.0243 - auc:  1.0000 - val_binary_crossentropy:  0.9710 - val_auc:  0.3773\n",
      "Epoch 18/100\n",
      "68s - loss:  0.0207 - binary_crossentropy:  0.0207 - auc:  1.0000 - val_binary_crossentropy:  0.9955 - val_auc:  0.3773\n",
      "Epoch 19/100\n",
      "67s - loss:  0.0180 - binary_crossentropy:  0.0180 - auc:  1.0000 - val_binary_crossentropy:  1.0177 - val_auc:  0.3727\n",
      "Epoch 20/100\n",
      "69s - loss:  0.0159 - binary_crossentropy:  0.0159 - auc:  1.0000 - val_binary_crossentropy:  1.0385 - val_auc:  0.3818\n",
      "Epoch 21/100\n",
      "70s - loss:  0.0142 - binary_crossentropy:  0.0142 - auc:  1.0000 - val_binary_crossentropy:  1.0569 - val_auc:  0.3818\n",
      "Epoch 22/100\n",
      "69s - loss:  0.0128 - binary_crossentropy:  0.0128 - auc:  1.0000 - val_binary_crossentropy:  1.0779 - val_auc:  0.3864\n",
      "Epoch 23/100\n",
      "69s - loss:  0.0117 - binary_crossentropy:  0.0117 - auc:  1.0000 - val_binary_crossentropy:  1.0871 - val_auc:  0.3818\n",
      "Epoch 24/100\n",
      "69s - loss:  0.0107 - binary_crossentropy:  0.0107 - auc:  1.0000 - val_binary_crossentropy:  1.1111 - val_auc:  0.3818\n",
      "Epoch 25/100\n",
      "69s - loss:  0.0099 - binary_crossentropy:  0.0099 - auc:  1.0000 - val_binary_crossentropy:  1.1213 - val_auc:  0.3818\n",
      "Epoch 26/100\n",
      "69s - loss:  0.0092 - binary_crossentropy:  0.0092 - auc:  1.0000 - val_binary_crossentropy:  1.1401 - val_auc:  0.3818\n",
      "Epoch 27/100\n",
      "69s - loss:  0.0085 - binary_crossentropy:  0.0085 - auc:  1.0000 - val_binary_crossentropy:  1.1489 - val_auc:  0.3818\n",
      "Epoch 28/100\n",
      "69s - loss:  0.0080 - binary_crossentropy:  0.0080 - auc:  1.0000 - val_binary_crossentropy:  1.1661 - val_auc:  0.3818\n",
      "Epoch 29/100\n",
      "69s - loss:  0.0075 - binary_crossentropy:  0.0075 - auc:  1.0000 - val_binary_crossentropy:  1.1726 - val_auc:  0.3818\n",
      "Epoch 30/100\n",
      "67s - loss:  0.0071 - binary_crossentropy:  0.0071 - auc:  1.0000 - val_binary_crossentropy:  1.1886 - val_auc:  0.3818\n",
      "Epoch 31/100\n",
      "69s - loss:  0.0067 - binary_crossentropy:  0.0067 - auc:  1.0000 - val_binary_crossentropy:  1.1977 - val_auc:  0.3818\n",
      "Epoch 32/100\n",
      "68s - loss:  0.0063 - binary_crossentropy:  0.0063 - auc:  1.0000 - val_binary_crossentropy:  1.2097 - val_auc:  0.3818\n",
      "Epoch 33/100\n",
      "71s - loss:  0.0060 - binary_crossentropy:  0.0060 - auc:  1.0000 - val_binary_crossentropy:  1.2190 - val_auc:  0.3818\n",
      "Epoch 34/100\n",
      "79s - loss:  0.0057 - binary_crossentropy:  0.0057 - auc:  1.0000 - val_binary_crossentropy:  1.2271 - val_auc:  0.3818\n",
      "Epoch 35/100\n",
      "80s - loss:  0.0054 - binary_crossentropy:  0.0054 - auc:  1.0000 - val_binary_crossentropy:  1.2373 - val_auc:  0.3818\n",
      "Epoch 36/100\n",
      "80s - loss:  0.0052 - binary_crossentropy:  0.0052 - auc:  1.0000 - val_binary_crossentropy:  1.2469 - val_auc:  0.3818\n",
      "Epoch 37/100\n",
      "80s - loss:  0.0050 - binary_crossentropy:  0.0050 - auc:  1.0000 - val_binary_crossentropy:  1.2560 - val_auc:  0.3818\n",
      "Epoch 38/100\n",
      "79s - loss:  0.0047 - binary_crossentropy:  0.0047 - auc:  1.0000 - val_binary_crossentropy:  1.2625 - val_auc:  0.3818\n",
      "Epoch 39/100\n",
      "81s - loss:  0.0046 - binary_crossentropy:  0.0046 - auc:  1.0000 - val_binary_crossentropy:  1.2725 - val_auc:  0.3818\n",
      "Epoch 40/100\n",
      "75s - loss:  0.0044 - binary_crossentropy:  0.0044 - auc:  1.0000 - val_binary_crossentropy:  1.2791 - val_auc:  0.3818\n",
      "Epoch 41/100\n",
      "69s - loss:  0.0042 - binary_crossentropy:  0.0042 - auc:  1.0000 - val_binary_crossentropy:  1.2873 - val_auc:  0.3818\n",
      "Epoch 42/100\n",
      "69s - loss:  0.0040 - binary_crossentropy:  0.0040 - auc:  1.0000 - val_binary_crossentropy:  1.2926 - val_auc:  0.3818\n",
      "Epoch 43/100\n",
      "68s - loss:  0.0039 - binary_crossentropy:  0.0039 - auc:  1.0000 - val_binary_crossentropy:  1.3026 - val_auc:  0.3818\n",
      "Epoch 44/100\n",
      "69s - loss:  0.0038 - binary_crossentropy:  0.0038 - auc:  1.0000 - val_binary_crossentropy:  1.3049 - val_auc:  0.3818\n",
      "Epoch 45/100\n",
      "69s - loss:  0.0036 - binary_crossentropy:  0.0036 - auc:  1.0000 - val_binary_crossentropy:  1.3150 - val_auc:  0.3818\n",
      "Epoch 46/100\n",
      "69s - loss:  0.0035 - binary_crossentropy:  0.0035 - auc:  1.0000 - val_binary_crossentropy:  1.3195 - val_auc:  0.3818\n",
      "Epoch 47/100\n",
      "69s - loss:  0.0034 - binary_crossentropy:  0.0034 - auc:  1.0000 - val_binary_crossentropy:  1.3289 - val_auc:  0.3773\n",
      "Epoch 48/100\n",
      "68s - loss:  0.0033 - binary_crossentropy:  0.0033 - auc:  1.0000 - val_binary_crossentropy:  1.3318 - val_auc:  0.3773\n",
      "Epoch 49/100\n",
      "69s - loss:  0.0032 - binary_crossentropy:  0.0032 - auc:  1.0000 - val_binary_crossentropy:  1.3410 - val_auc:  0.3773\n",
      "Epoch 50/100\n",
      "68s - loss:  0.0031 - binary_crossentropy:  0.0031 - auc:  1.0000 - val_binary_crossentropy:  1.3426 - val_auc:  0.3773\n",
      "Epoch 51/100\n",
      "69s - loss:  0.0030 - binary_crossentropy:  0.0030 - auc:  1.0000 - val_binary_crossentropy:  1.3515 - val_auc:  0.3773\n",
      "Epoch 52/100\n",
      "69s - loss:  0.0029 - binary_crossentropy:  0.0029 - auc:  1.0000 - val_binary_crossentropy:  1.3553 - val_auc:  0.3773\n",
      "Epoch 53/100\n",
      "68s - loss:  0.0028 - binary_crossentropy:  0.0028 - auc:  1.0000 - val_binary_crossentropy:  1.3632 - val_auc:  0.3773\n",
      "Epoch 54/100\n",
      "68s - loss:  0.0027 - binary_crossentropy:  0.0027 - auc:  1.0000 - val_binary_crossentropy:  1.3660 - val_auc:  0.3773\n",
      "Epoch 55/100\n",
      "69s - loss:  0.0027 - binary_crossentropy:  0.0027 - auc:  1.0000 - val_binary_crossentropy:  1.3735 - val_auc:  0.3773\n",
      "Epoch 56/100\n",
      "69s - loss:  0.0026 - binary_crossentropy:  0.0026 - auc:  1.0000 - val_binary_crossentropy:  1.3756 - val_auc:  0.3773\n",
      "Epoch 57/100\n",
      "68s - loss:  0.0025 - binary_crossentropy:  0.0025 - auc:  1.0000 - val_binary_crossentropy:  1.3833 - val_auc:  0.3773\n",
      "Epoch 58/100\n",
      "68s - loss:  0.0025 - binary_crossentropy:  0.0025 - auc:  1.0000 - val_binary_crossentropy:  1.3861 - val_auc:  0.3773\n",
      "Epoch 59/100\n",
      "69s - loss:  0.0024 - binary_crossentropy:  0.0024 - auc:  1.0000 - val_binary_crossentropy:  1.3932 - val_auc:  0.3773\n",
      "Epoch 60/100\n",
      "69s - loss:  0.0023 - binary_crossentropy:  0.0023 - auc:  1.0000 - val_binary_crossentropy:  1.3954 - val_auc:  0.3773\n",
      "Epoch 61/100\n",
      "68s - loss:  0.0023 - binary_crossentropy:  0.0023 - auc:  1.0000 - val_binary_crossentropy:  1.4021 - val_auc:  0.3773\n",
      "Epoch 62/100\n",
      "69s - loss:  0.0022 - binary_crossentropy:  0.0022 - auc:  1.0000 - val_binary_crossentropy:  1.4039 - val_auc:  0.3773\n",
      "Epoch 63/100\n",
      "69s - loss:  0.0022 - binary_crossentropy:  0.0022 - auc:  1.0000 - val_binary_crossentropy:  1.4107 - val_auc:  0.3773\n",
      "Epoch 64/100\n",
      "69s - loss:  0.0021 - binary_crossentropy:  0.0021 - auc:  1.0000 - val_binary_crossentropy:  1.4137 - val_auc:  0.3773\n",
      "Epoch 65/100\n",
      "68s - loss:  0.0021 - binary_crossentropy:  0.0021 - auc:  1.0000 - val_binary_crossentropy:  1.4196 - val_auc:  0.3773\n",
      "Epoch 66/100\n",
      "70s - loss:  0.0020 - binary_crossentropy:  0.0020 - auc:  1.0000 - val_binary_crossentropy:  1.4213 - val_auc:  0.3773\n",
      "Epoch 67/100\n",
      "72s - loss:  0.0020 - binary_crossentropy:  0.0020 - auc:  1.0000 - val_binary_crossentropy:  1.4274 - val_auc:  0.3773\n",
      "Epoch 68/100\n",
      "72s - loss:  0.0020 - binary_crossentropy:  0.0020 - auc:  1.0000 - val_binary_crossentropy:  1.4303 - val_auc:  0.3727\n",
      "Epoch 69/100\n",
      "71s - loss:  0.0019 - binary_crossentropy:  0.0019 - auc:  1.0000 - val_binary_crossentropy:  1.4356 - val_auc:  0.3727\n",
      "Epoch 70/100\n",
      "71s - loss:  0.0019 - binary_crossentropy:  0.0019 - auc:  1.0000 - val_binary_crossentropy:  1.4376 - val_auc:  0.3727\n",
      "Epoch 71/100\n",
      "72s - loss:  0.0018 - binary_crossentropy:  0.0018 - auc:  1.0000 - val_binary_crossentropy:  1.4433 - val_auc:  0.3727\n",
      "Epoch 72/100\n",
      "71s - loss:  0.0018 - binary_crossentropy:  0.0018 - auc:  1.0000 - val_binary_crossentropy:  1.4449 - val_auc:  0.3727\n",
      "Epoch 73/100\n",
      "70s - loss:  0.0018 - binary_crossentropy:  0.0018 - auc:  1.0000 - val_binary_crossentropy:  1.4507 - val_auc:  0.3727\n",
      "Epoch 74/100\n",
      "70s - loss:  0.0017 - binary_crossentropy:  0.0017 - auc:  1.0000 - val_binary_crossentropy:  1.4520 - val_auc:  0.3727\n",
      "Epoch 75/100\n",
      "71s - loss:  0.0017 - binary_crossentropy:  0.0017 - auc:  1.0000 - val_binary_crossentropy:  1.4577 - val_auc:  0.3727\n",
      "Epoch 76/100\n",
      "71s - loss:  0.0017 - binary_crossentropy:  0.0017 - auc:  1.0000 - val_binary_crossentropy:  1.4603 - val_auc:  0.3682\n",
      "Epoch 77/100\n",
      "71s - loss:  0.0016 - binary_crossentropy:  0.0016 - auc:  1.0000 - val_binary_crossentropy:  1.4652 - val_auc:  0.3682\n",
      "Epoch 78/100\n",
      "358s - loss:  0.0016 - binary_crossentropy:  0.0016 - auc:  1.0000 - val_binary_crossentropy:  1.4666 - val_auc:  0.3682\n",
      "Epoch 79/100\n",
      "7118s - loss:  0.0016 - binary_crossentropy:  0.0016 - auc:  1.0000 - val_binary_crossentropy:  1.4718 - val_auc:  0.3682\n",
      "Epoch 80/100\n",
      "15174s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.4742 - val_auc:  0.3682\n",
      "Epoch 81/100\n",
      "4850s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.4784 - val_auc:  0.3682\n",
      "Epoch 82/100\n",
      "71s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.4804 - val_auc:  0.3682\n",
      "Epoch 83/100\n",
      "70s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.4850 - val_auc:  0.3682\n",
      "Epoch 84/100\n",
      "69s - loss:  0.0014 - binary_crossentropy:  0.0014 - auc:  1.0000 - val_binary_crossentropy:  1.4859 - val_auc:  0.3682\n",
      "Epoch 85/100\n",
      "68s - loss:  0.0014 - binary_crossentropy:  0.0014 - auc:  1.0000 - val_binary_crossentropy:  1.4910 - val_auc:  0.3682\n",
      "Epoch 86/100\n",
      "68s - loss:  0.0014 - binary_crossentropy:  0.0014 - auc:  1.0000 - val_binary_crossentropy:  1.4933 - val_auc:  0.3682\n",
      "Epoch 87/100\n",
      "68s - loss:  0.0014 - binary_crossentropy:  0.0014 - auc:  1.0000 - val_binary_crossentropy:  1.4975 - val_auc:  0.3682\n",
      "Epoch 88/100\n",
      "68s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.5001 - val_auc:  0.3682\n",
      "Epoch 89/100\n",
      "68s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.5032 - val_auc:  0.3682\n",
      "Epoch 90/100\n",
      "68s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.5055 - val_auc:  0.3682\n",
      "Epoch 91/100\n",
      "69s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.5092 - val_auc:  0.3682\n",
      "Epoch 92/100\n",
      "69s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.5117 - val_auc:  0.3682\n",
      "Epoch 93/100\n",
      "69s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.5149 - val_auc:  0.3682\n",
      "Epoch 94/100\n",
      "69s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.5170 - val_auc:  0.3682\n",
      "Epoch 95/100\n",
      "69s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.5205 - val_auc:  0.3682\n",
      "Epoch 96/100\n",
      "68s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.5228 - val_auc:  0.3682\n",
      "Epoch 97/100\n",
      "69s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.5260 - val_auc:  0.3682\n",
      "Epoch 98/100\n",
      "69s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.5282 - val_auc:  0.3682\n",
      "Epoch 99/100\n",
      "69s - loss:  0.0011 - binary_crossentropy:  0.0011 - auc:  1.0000 - val_binary_crossentropy:  1.5311 - val_auc:  0.3682\n",
      "Epoch 100/100\n",
      "70s - loss:  0.0011 - binary_crossentropy:  0.0011 - auc:  1.0000 - val_binary_crossentropy:  1.5335 - val_auc:  0.3682\n",
      "\n",
      "test LogLoss 1.1997\n",
      "test AUC 0.4122\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型，进行训练和预测\n",
    "\n",
    "model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns, task='binary',\n",
    "               l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "               metrics=[\"binary_crossentropy\", \"auc\"],)\n",
    "model.fit(train_model_input, train[target].values,\n",
    "           batch_size=256, epochs=100, validation_split=0.2, verbose=2)\n",
    "\n",
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 summary 可视化 模型结构,以前叫 torch_summary,现在叫 torchinfo\n",
    "\n",
    "```shel\n",
    "conda install -c conda-forge torchinfo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用 torch_summary 进行可视化\n",
    "from torchinfo import summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "t = model.to(device)\n",
    "summary(t, input_size=(1, len(fixlen_feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a44de2e36693e10d3b38798396abd77400ab0347a65d80540105a567bba1b8e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
